# YOLOv5 ðŸš€ by Ultralytics, GPL-3.0 license
import argparse
import ctypes
import os
import platform
import sys
from pathlib import Path
import time
import torch
import serial
import cv2
from PyQt5 import QtCore
from PyQt5.QtWidgets import QApplication, QWidget, QLabel, QPushButton, QMessageBox, QVBoxLayout, QTextEdit, QCheckBox
from PyQt5.QtGui import QImage, QPixmap, QFont, QPalette, QBrush, QIcon
from PyQt5.QtCore import QTimer, QSize
import numpy as np

FILE = Path(__file__).resolve()#èŽ·å–å½“å‰ç›®å½•(detect.py)çš„(ä½¿ç”¨relsove)ç»å¯¹è·¯å¾„,å¹¶å°†å…¶èµ‹å€¼ç»™å˜é‡FILE F:\yolov5-7.0\mydetect.py
ROOT = FILE.parents[0]  # YOLOv5 root directory èŽ·å–ä¸Šä¸€çº§ç›®å½• F:\yolov5-7.0
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))  # add ROOT to PATH
ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relativeï¼Œç»å¯¹è·¯å¾„è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„ F:\yolov5-7.0\mydetect.py
from models.common import DetectMultiBackend
from utils.general import non_max_suppression
from utils.torch_utils import select_device
#å®šä¹‰äº†ä¸€å…±uiçš„ç±»
#black = np.zeros((480, 640, 3), dtype=np.uint8)

class CameraUI(QWidget):
    def __init__(self):
        super().__init__()
        self.detsign = False
        self.detcount = 0
        multiprocessing=torch.multiprocessing
        self.infor_sign = True
        self.lock_count = []
        self.lock = multiprocessing.Lock()
        self.shared_int = multiprocessing.Value('i', 1)
        manager = multiprocessing.Manager()
        self.shared_dict = manager.dict()
        #ä¸²å£
        self.queue = multiprocessing.Queue()
        self.shared_value = multiprocessing.Value('i', 0)
        # åˆ›å»ºManagerå¯¹è±¡ç”¨äºŽåˆ›å»ºå…±äº«å˜é‡
        self.shared_var = manager.Namespace()
        self.shared_var.np_frame = np.zeros((600, 800, 3), dtype=np.uint8)
        self.shared_det = manager.Namespace()
        self.shared_det.np_frame = np.zeros((600, 800, 3), dtype=np.uint8)
        self.initUI()
        self.detectUI()
        self.videoUI()
        self.show()

        self.cap = cv2.VideoCapture(1)
        if not self.cap.isOpened():
            QMessageBox.critical(self, "Error", "Unable to open camera", QMessageBox.Ok)
            self.close()
        ret2, frame2 = self.cap.read()
        if ret2:
            frame2 = cv2.resize(frame2, (800, 600))
            self.shared_var.np_frame = frame2

        self.video = cv2.VideoCapture('è§†é¢‘.mp4')
        if not self.video.isOpened():
            QMessageBox.critical(self, "é”™è¯¯", "æ— æ³•åŠ è½½è§†é¢‘", QMessageBox.Ok)
            self.close()

        #ä¸²å£è¿›ç¨‹
        ser_proeww = multiprocessing.Process(target=myserial, args=(self.queue, self.shared_value,))
        #æœºå™¨è¯†åˆ«è¿›ç¨‹
        self.detect_process = yolov5_detect(self.shared_dict, self.shared_var , self.lock,  self.shared_int,self.shared_det)
        self.detect_process.start()
        self.timer = QTimer()
        self.timer.timeout.connect(self.open_vidadet)
        self.timer.start()


    def initUI(self):
        self.setWindowTitle("æ™ºèƒ½åˆ†ç±»åžƒåœ¾æ¡¶")
        self.setGeometry(0, 0, 1080, 600)
        pixmap = QPixmap('çª—å£èƒŒæ™¯.png')
        # åˆ›å»ºè°ƒè‰²æ¿
        palette = QPalette()
        palette.setBrush(QPalette.Background, QBrush(pixmap))
        self.setPalette(palette)
    def detectUI(self):
        self.labeld = QLabel(self)
        self.labeld.setGeometry(220, 0, 640, 480)
        self.labeld.setStyleSheet("border-width: 10;"
                                 "border-color: white;"
                                 "background-color: black;")
        #æ»¡è½½åŒºåŸŸ
        self.title_label = QLabel(self)
        self.title_label.setText("æ™º èƒ½ åˆ† ç±» åžƒ åœ¾ æ¡¶")
        self.title_label.setGeometry(300, 500, 500, 50)
        # è®¾ç½®æ ·å¼
        self.title_label.setStyleSheet("font-size: 40px; font-weight: bold; border: 2px solid #d3d3d3; color: white;")

        self.labela = QLabel('å››ä¸ªåžƒåœ¾æ¡¶æ»¡è½½æƒ…å†µ', self)
        self.labela.setGeometry(870, 0, 210, 50)
        self.labela.setFont(QFont("Arial", 14))
        self.labela.setStyleSheet("color: yellow;")

        self.label0 = QLabel('0%', self)
        self.label0.setGeometry(970, 50, 100, 30)
        self.label0.setFont(QFont("Arial", 10))
        self.label0.setStyleSheet("color: green;"
                                  "background-color: white;")
        self.label1 = QLabel('0%', self)
        self.label1.setGeometry(970, 100, 100, 30)
        self.label1.setFont(QFont("Arial", 10))
        self.label1.setStyleSheet("color: green;"
                                  "background-color: white;")
        self.label2 = QLabel('0%', self)
        self.label2.setFont(QFont("Arial", 10))
        self.label2.setGeometry(970, 150, 100, 30)
        self.label2.setStyleSheet("color: green;"
                                  "background-color: white;")
        self.label3 = QLabel('0%', self)
        self.label3.setFont(QFont("Arial", 10))
        self.label3.setGeometry(970, 200, 100, 30)
        self.label3.setStyleSheet("color: green;"
                                  "background-color: white;")
        self.btn1 = QLabel('å…¶ä»–åžƒåœ¾:', self)
        self.btn1.setFont(QFont("Arial", 10))
        self.btn1.setStyleSheet("color: white;")
        self.btn1.setGeometry(870, 50, 100, 30)

        self.btn2 = QLabel('æœ‰å®³åžƒåœ¾:', self)
        self.btn2.setFont(QFont("Arial", 10))
        self.btn2.setStyleSheet("color: white;")
        self.btn2.setGeometry(870, 100, 100, 30)

        self.btn3 = QLabel('åŽ¨ä½™åžƒåœ¾:', self)
        self.btn3.setFont(QFont("Arial", 10))
        self.btn3.setStyleSheet("color: white;")
        self.btn3.setGeometry(870, 150, 100, 30)

        self.btn4 = QLabel('å¯å›žæ”¶åžƒåœ¾:', self)
        self.btn4.setFont(QFont("Arial", 10))
        self.btn4.setStyleSheet("color: white;")
        self.btn4.setGeometry(870, 200, 100, 30)
        #æ£€æµ‹ä¿¡æ¯åŒºåŸŸ
        self.reportlabel = QLabel(self)
        self.reportlabel.setText("æ£€æµ‹ä¿¡æ¯: ")
        self.reportlabel.setGeometry(0, 0, 150, 50)
        self.reportlabel.setFont(QFont("Arial", 16))
        self.reportlabel.setStyleSheet("color: white;font-weight: bold;")
        self.report = QLabel(self)
        self.report.setGeometry(0, 50, 220, 435)
        self.report.setFont(QFont("Arial", 13))
        self.report.setAlignment(QtCore.Qt.AlignTop)
        self.report.setStyleSheet("color: red;"  # è®¾ç½®æ–‡æœ¬æ˜¾ç¤ºåŒºåŸŸæ ·å¼
                                  "background-color: white;"
                                  "border-style: outset;"
                                  "border-width: 5;"
                                  "border-radius: 0;"
                                  "border-color: black;")

    def videoUI(self):
        # æ˜¾ç¤ºåŒºåŸŸ
        self.label = QLabel(self)
        self.label.setGeometry(0, 0, 1080, 600)
        self.label.setStyleSheet("border-width: 10;"
                                 "border-color: white;"
                                 "background-color: black;")


    def open_vidadet(self):
        if self.detcount >0:
            self.detcount-=1
        if not self.shared_dict and not self.detcount:
            ret, frame = self.video.read()
            self.detsign = False
            self.label.show()
        else:
            ret ,self.detsign = True ,True
            if self.shared_dict:
                self.detcount = 50
            frame = self.shared_det.np_frame
            self.label.hide()

        ret2, frame2 = self.cap.read()
        if ret2 and not self.shared_int.value:
            frame2 = cv2.resize(frame2, (800, 600))
            self.lock.acquire()
            self.shared_var.np_frame = frame2
            self.lock.release()
            self.shared_int.value = 1
        if not ret:
            # åˆ°è¾¾è§†é¢‘ç»“å°¾ï¼Œå°†VideoCaptureå¯¹è±¡çš„ä½ç½®è®¾ç½®ä¸º0ï¼Œå³é‡æ–°æ’­æ”¾è§†é¢‘
            self.video.set(cv2.CAP_PROP_POS_FRAMES, 0)
            return
        self.up_frame(frame,1080,600) if not self.detsign else self.up_frame(frame, 640, 480)
        #print('dict: ',self.shared_dict)


    def up_frame(self,frame,vw,vh):
        frame = cv2.resize(frame,(vw,vh))
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        h, w, ch = frame.shape
        bytesPerLine = ch * w
        convertToQtFormat = QImage(frame.data, w, h, bytesPerLine, QImage.Format_RGB888)
        p = convertToQtFormat.scaled(vw, vh, aspectRatioMode=1, transformMode=0)
        self.label.setPixmap(QPixmap.fromImage(p)) if not self.detsign else self.labeld.setPixmap(QPixmap.fromImage(p))
        if self.detsign:
            print('sign:',self.infor_sign)
            self.detectinfor() if self.infor_sign else "pass"
            self.dp_infor()

    def detectinfor(self):
        count = 1
        # è¯†åˆ«åˆ°çš„åžƒåœ¾ç§ç±»ï¼Œåºå·ï¼ŒçŠ¶æ€ï¼Œä¸­å¿ƒåæ ‡
        self.waste_type = [''] * 10
        self.waste_num = []
        self.waste_statu = [''] * 10
        self.waste_address = np.empty(10, dtype=object)
        self.lock.acquire()
        for mkey,mvalue in self.shared_dict.items():

            if mkey[0]=='e':
                type = 'å…¶ä»–åžƒåœ¾'
            elif mkey[0]=='h':
                type = 'æœ‰å®³åžƒåœ¾'
            elif mkey[0] == 'k':
                type = 'åŽ¨ä½™åžƒåœ¾'
            elif mkey[0] == 'r':
                type = 'å¯å›žæ”¶åžƒåœ¾'
            else:
                pass
            self.waste_num.append(count)
            self.waste_type[count] = type
            self.waste_statu[count] = 'å¾…å¤„ç†'
            self.waste_address[count] = [(mvalue[0]+mvalue[2])//2,(mvalue[1]+mvalue[3])//2]
            count +=1
        self.lock.release()
        self.lock_count.append(count)
        if len(self.lock_count)>10:
            self.infor_sign = False if max(self.lock_count)==min(self.lock_count) else True
            self.lock_count.clear()
    def dp_infor(self):
        if self.infor_sign:
            self.reportext = ['']*10
            for i in self.waste_num:
                self.reportext[i-1]=f'{i}--'+self.waste_type[i] +'--'+self.waste_statu[i]
        else:

            self.lock.acquire()
            self.queue.put(self.shared_dict)
            self.lock.release()
        print(4)
        self.report.setText(self.reportext[0]+'\n'+self.reportext[1]+'\n'+self.reportext[2]+'\n')

def myserial(queue,shared_value):
    ser = serial.Serial('ttyUSB0', 9600, timeout=1)# æ‰“å¼€ä¸²å£
    #ä¸²å£æ‰“å¼€æˆåŠŸ
    print('ä¸²å£æ‰“å¼€æˆåŠŸ')
    statue = True
    count ,coord= 0,[]
    try:
        while True:
            for i in range(3):
                data = queue.get()
                waste_type,waste_coor = list(data.key()),list(data.value())
                for type,(x0,y0,x1,y1) in waste_type,waste_coor:
                    x ,y = str((x0 + x1) // 2),str((y0 + y1) // 2)
                    x = '00' + str(x) if len(str(x)) == 1 else x
                    y = '00' + str(y) if len(str(y)) == 1 else y
                    x = '0' + str(x) if len(str(x)) == 2 else x
                    y = '0' + str(y) if len(str(y)) == 2 else y
                    co = x+y
                    coord.append(co)

            for t,c in waste_type,coord:
                ser.write(t.encode())
                time.sleep(0.1)
                ser.write(c.encode())
                time.sleep(0.1)
            ser.write(b'o')
            while True:
                res = ser.read()
                res = res.decode()
                if res == '1':
                    print('å‘é€ä¸€æ¬¡æˆåŠŸ')
                    break
                elif res == '2':
                    print('å‘é€å¤±è´¥ï¼Œå‡†å¤‡é‡å‘')
                    break              # åœ¨æ­¤å¤„æ‰§è¡Œå…¶ä»–æ“ä½œ
    finally:
        # å…³é—­ä¸²å£
        if ser.is_open:
            ser.close()

class yolov5_detect(torch.multiprocessing.Process):
    def __init__(self, share_dict, share_frame,lock, shared_int , shared_det, weights='yolov5s.pt', device='cpu', conf_thres=0.8, iou_thres=1.0):
        super().__init__()
        self.shared_int = shared_int
        self.lock = lock
        self.shared_dict = share_dict
        self.shared_frame = share_frame
        self.shared_det = shared_det
        self.retu = {}
        self.classes = ['else waste', 'hazardous', 'kitchen', 'recyclable']
        device = select_device(device=device)
        self.model = DetectMultiBackend(weights, device=device, dnn=False, data='data/coco128.yaml', fp16=False)
        self.device = device
        self.weights = weights
        self.conf_thres = conf_thres
        self.iou_thres = iou_thres

    def run(self):
        while True:
            if self.shared_int.value:
                self.lock.acquire()
                self.frame =  self.shared_frame.np_frame
                self.lock.release()
                print('è¯»å–ä¸€å¼ æˆåŠŸ')
                self.shared_int.value = 0
                self.retu = {}
                count, C = 0, []
                lase_type = []
                t = time.time()
                self.frame = cv2.resize(self.frame, (800, 600))
                self.frame = self.frame[(600 // 2 - 240):(600 // 2 + 240), (800 // 2 - 320):(800 // 2 + 320)]
                self.img = cv2.cvtColor(self.frame, cv2.COLOR_BGR2RGB)
                self.img = torch.from_numpy(self.img).to(self.device).float() / 255.0
                self.img = self.img.permute(2, 0, 1).unsqueeze(0)
                if len(self.img.shape) == 3:
                    self.img = self.img[None]  # expand for batch dimå¦‚æžœå¼ é‡çš„ç»´åº¦ä¸º 3ï¼Œåˆ™åœ¨ç¬¬ 0 ç»´ä¸Šæ·»åŠ ä¸€ä¸ªç»´åº¦ï¼Œä»¥ä¾¿å°†å…¶æ‰©å±•ä¸ºæ‰¹æ¬¡å¤§å°ä¸º 1 çš„å¼ é‡ã€‚
                self.pre = self.model.model(self.img, augment=False)  # è°ƒç”¨ YOLOv5 æ¨¡åž‹çš„ model æ–¹æ³•ï¼Œå¯¹è¾“å…¥çš„å›¾åƒæˆ–è§†é¢‘è¿›è¡ŒæŽ¨ç†ï¼Œå¹¶å¾—åˆ°ç›®æ ‡æ£€æµ‹ç»“æžœã€‚
                self.pred = non_max_suppression(self.pre, self.conf_thres, self.iou_thres, None, False, max_det=10)

                for det in self.pred[0]:
                    count += 1
                    if count > 1:
                        for [a, b] in C:
                            q = abs(int(det[0]) - a)
                            w = abs(int(det[1]) - b)
                            if q <= 5 and w <= 5:
                                ab = False
                                break
                            ab = True
                    else:
                        ab = True
                    if ab:
                        xyxy = (det[0], det[1], det[2], det[3])
                        cls = det[5]
                        conf = det[4]
                        ty = self.classes[int(cls)] + str(count) if int(det[5]) in lase_type else self.classes[int(cls)]
                        self.retu[ty] = list(int(x) for x in xyxy)
                        label = f'{self.classes[int(cls)]} {conf:.2f}'
                        cv2.rectangle(self.frame, (int(xyxy[0]), int(xyxy[1])), (int(xyxy[2]), int(xyxy[3])), (0, 255, 0),
                                      2)
                        cv2.putText(self.frame, label, (int(xyxy[0]), int(xyxy[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,
                                    (0, 255, 0), 2)
                        lase_type.append(int(det[5]))
                    C.append([int(det[0]), int(det[1])])
                self.shared_det.np_frame = self.frame
                self.lock.acquire()
                self.shared_dict.clear()
                self.shared_dict.update(self.retu)
                self.lock.release()
                print('self.shared_dict: ',self.shared_dict)
                t = time.time() - t

    def date_intaract(self):
        self.shared_dict = self.retu
        self.shared_frame = self.frame

if __name__=='__main__':

    app = QApplication(sys.argv)
    ex = CameraUI()
    sys.exit(app.exec_())

