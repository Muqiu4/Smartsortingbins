# YOLOv5 ðŸš€ by Ultralytics, GPL-3.0 license
import argparse
import ctypes
import os
import platform
import sys
from pathlib import Path
import time
import torch
import serial
import cv2
from multiprocessing import Process, Queue, Value, shared_memory
from PyQt5.QtWidgets import QApplication, QWidget, QLabel, QPushButton, QMessageBox, QVBoxLayout, QTextEdit, QCheckBox
from PyQt5.QtGui import QImage, QPixmap, QFont, QPalette, QBrush, QIcon
from PyQt5.QtCore import QTimer, QSize
import numpy as np
import multiprocessing
FILE = Path(__file__).resolve()#èŽ·å–å½“å‰ç›®å½•(detect.py)çš„(ä½¿ç”¨relsove)ç»å¯¹è·¯å¾„,å¹¶å°†å…¶èµ‹å€¼ç»™å˜é‡FILE F:\yolov5-7.0\mydetect.py
ROOT = FILE.parents[0]  # YOLOv5 root directory èŽ·å–ä¸Šä¸€çº§ç›®å½• F:\yolov5-7.0
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))  # add ROOT to PATH
ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relativeï¼Œç»å¯¹è·¯å¾„è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„ F:\yolov5-7.0\mydetect.py
from models.common import DetectMultiBackend
from utils.general import non_max_suppression
from utils.torch_utils import select_device
#å®šä¹‰äº†ä¸€å…±uiçš„ç±»
#black = np.zeros((480, 640, 3), dtype=np.uint8)

class CameraUI(QWidget):
    def __init__(self):
        super().__init__()

        self.lock = multiprocessing.Lock()
        self.shared_int = multiprocessing.Value('i', 1)
        manager = multiprocessing.Manager()
        self.shared_dict = manager.dict()

        # åˆ›å»ºManagerå¯¹è±¡ç”¨äºŽåˆ›å»ºå…±äº«å˜é‡
        self.shared_var = manager.Namespace()
        self.shared_var.np_frame = np.zeros((600, 800, 3), dtype=np.uint8)

        self.initUI()
        #self.detectUI()
        self.videoUI()
        self.show()

        self.cap = cv2.VideoCapture(0)
        if not self.cap.isOpened():
            QMessageBox.critical(self, "Error", "Unable to open camera", QMessageBox.Ok)
            self.close()
        ret2, frame2 = self.cap.read()
        if ret2:
            frame2 = cv2.resize(frame2, (800, 600))
            self.shared_var.np_frame = frame2

        self.video = cv2.VideoCapture('è§†é¢‘.mp4')
        if not self.video.isOpened():
            QMessageBox.critical(self, "é”™è¯¯", "æ— æ³•åŠ è½½è§†é¢‘", QMessageBox.Ok)
            self.close()

        self.detect_process = yolov5_detect(self.shared_dict, self.shared_var , self.lock,  self.shared_int)
        self.detect_process.start()
        self.timer = QTimer()
        self.timer.timeout.connect(self.open_video)
        self.timer.start()


    def initUI(self):
        self.setWindowTitle("æ™ºèƒ½åˆ†ç±»åžƒåœ¾æ¡¶")
        self.setGeometry(0, 0, 1080, 600)
        pixmap = QPixmap('çª—å£èƒŒæ™¯.png')
        # åˆ›å»ºè°ƒè‰²æ¿
        palette = QPalette()
        palette.setBrush(QPalette.Background, QBrush(pixmap))
        self.setPalette(palette)
    def detectUI(self):

        #æ»¡è½½åŒºåŸŸ
        self.title_label = QLabel(self)
        self.title_label.setText("æ™º èƒ½ åˆ† ç±» åžƒ åœ¾ æ¡¶")
        self.title_label.setGeometry(250, 550, 500, 50)
        # è®¾ç½®æ ·å¼
        self.title_label.setStyleSheet("font-size: 40px; font-weight: bold; border: 2px solid #d3d3d3; color: white;")

        self.labela = QLabel('å››ä¸ªåžƒåœ¾æ¡¶æ»¡è½½æƒ…å†µ', self)
        self.labela.setGeometry(800, 0, 210, 50)
        self.labela.setFont(QFont("Arial", 14))
        self.labela.setStyleSheet("color: yellow;")

        self.label0 = QLabel('0%', self)
        self.label0.setGeometry(900, 50, 100, 30)
        self.label0.setFont(QFont("Arial", 10))
        self.label0.setStyleSheet("color: green;"
                                  "background-color: white;")
        self.label1 = QLabel('0%', self)
        self.label1.setGeometry(900, 100, 100, 30)
        self.label1.setFont(QFont("Arial", 10))
        self.label1.setStyleSheet("color: green;"
                                  "background-color: white;")
        self.label2 = QLabel('0%', self)
        self.label2.setFont(QFont("Arial", 10))
        self.label2.setGeometry(900, 150, 100, 30)
        self.label2.setStyleSheet("color: green;"
                                  "background-color: white;")
        self.label3 = QLabel('0%', self)
        self.label3.setFont(QFont("Arial", 10))
        self.label3.setGeometry(900, 200, 100, 30)
        self.label3.setStyleSheet("color: green;"
                                  "background-color: white;")
        self.btn1 = QLabel('å…¶ä»–åžƒåœ¾:', self)
        self.btn1.setFont(QFont("Arial", 10))
        self.btn1.setStyleSheet("color: white;")
        self.btn1.setGeometry(800, 50, 100, 30)

        self.btn2 = QLabel('æœ‰å®³åžƒåœ¾:', self)
        self.btn2.setFont(QFont("Arial", 10))
        self.btn2.setStyleSheet("color: white;")
        self.btn2.setGeometry(800, 100, 100, 30)

        self.btn3 = QLabel('åŽ¨ä½™åžƒåœ¾:', self)
        self.btn3.setFont(QFont("Arial", 10))
        self.btn3.setStyleSheet("color: white;")
        self.btn3.setGeometry(800, 150, 100, 30)

        self.btn4 = QLabel('å¯å›žæ”¶åžƒåœ¾:', self)
        self.btn4.setFont(QFont("Arial", 10))
        self.btn4.setStyleSheet("color: white;")
        self.btn4.setGeometry(800, 200, 100, 30)
        #æ£€æµ‹ä¿¡æ¯åŒºåŸŸ
        self.reportlabel = QLabel(self)
        self.reportlabel.setText("æ£€æµ‹ä¿¡æ¯: ")
        self.reportlabel.setGeometry(0, 0, 150, 50)
        self.reportlabel.setFont(QFont("Arial", 16))
        self.reportlabel.setStyleSheet("color: white;")
        self.report = QLabel(self)
        self.report.setGeometry(0, 50, 210, 500)
        self.report.setFont(QFont("Arial", 13))
        self.report.setStyleSheet("color: black;"  # è®¾ç½®æ–‡æœ¬æ˜¾ç¤ºåŒºåŸŸæ ·å¼
                                  "background-color: white;"
                                  "border-style: outset;"
                                  "border-width: 3;"
                                  "border-radius: 0;"
                                  "border-color: black;")

    def videoUI(self):
        # æ˜¾ç¤ºåŒºåŸŸ
        self.label = QLabel(self)
        self.label.setGeometry(0, 0, 1080, 600)
        self.label.setStyleSheet("border-width: 10;"
                                 "border-color: white;"
                                 "background-color: black;")


    def open_video(self):
        ret, frame = self.video.read()
        ret2, frame2 = self.cap.read()
        if ret2 and not self.shared_int.value:
            frame2 = cv2.resize(frame2, (800, 600))
            self.lock.acquire()
            self.shared_var.np_frame = frame2

            self.lock.release()
            self.shared_int.value = 1


        if not ret:
            # åˆ°è¾¾è§†é¢‘ç»“å°¾ï¼Œå°†VideoCaptureå¯¹è±¡çš„ä½ç½®è®¾ç½®ä¸º0ï¼Œå³é‡æ–°æ’­æ”¾è§†é¢‘
            self.video.set(cv2.CAP_PROP_POS_FRAMES, 0)
            return

        self.up_frame(frame,1080,600)
        if self.shared_dict:
            self.label.setGeometry(150, 0, 640, 480)
            self.timer.timeout.connect(self.open_detect)

    def open_detect(self):
        frame = self.shared_frame
        self.up_frame(frame,640,480)
    def up_frame(self,frame,vw,vh):
        frame = cv2.resize(frame,(1080,600))
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        h, w, ch = frame.shape
        bytesPerLine = ch * w
        convertToQtFormat = QImage(frame.data, w, h, bytesPerLine, QImage.Format_RGB888)
        p = convertToQtFormat.scaled(vw, vh, aspectRatioMode=1, transformMode=0)
        self.label.setPixmap(QPixmap.fromImage(p))



class yolov5_detect(multiprocessing.Process):
    def __init__(self, share_dict, share_frame,lock, shared_int ,weights='yolov5s.pt', device='cpu', conf_thres=0.8, iou_thres=1.0):
        super().__init__()
        self.shared_int = shared_int
        self.lock = lock
        self.shared_dict = share_dict
        self.shared_frame = share_frame
        self.retu = {}
        self.classes = ['else waste', 'hazardous', 'kitchen', 'recyclable']
        device = select_device(device=device)
        device = torch.device(device) if device else torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = DetectMultiBackend(weights, device=device, dnn=False, data='data/coco128.yaml', fp16=False)
        self.device = device
        self.weights = weights
        self.conf_thres = conf_thres
        self.iou_thres = iou_thres

    def run(self):
        while True:
            if self.shared_int.value:
                self.lock.acquire()
                self.frame =  self.shared_frame.np_frame
                self.lock.release()
                print('è¯»å–ä¸€å¼ æˆåŠŸ')
                self.shared_int.value = 0
                self.retu = {}
                count, C = 0, []
                lase_type = []
                t = time.time()
                self.frame = cv2.resize(self.frame, (800, 600))
                self.frame = self.frame[(600 // 2 - 240):(600 // 2 + 240), (800 // 2 - 320):(800 // 2 + 320)]
                self.img = cv2.cvtColor(self.frame, cv2.COLOR_BGR2RGB)
                self.img = torch.from_numpy(self.img).to(self.device).float() / 255.0
                self.img = self.img.permute(2, 0, 1).unsqueeze(0)
                if len(self.img.shape) == 3:
                    self.img = self.img[None]  # expand for batch dimå¦‚æžœå¼ é‡çš„ç»´åº¦ä¸º 3ï¼Œåˆ™åœ¨ç¬¬ 0 ç»´ä¸Šæ·»åŠ ä¸€ä¸ªç»´åº¦ï¼Œä»¥ä¾¿å°†å…¶æ‰©å±•ä¸ºæ‰¹æ¬¡å¤§å°ä¸º 1 çš„å¼ é‡ã€‚
                self.pre = self.model.model(self.img, augment=False)  # è°ƒç”¨ YOLOv5 æ¨¡åž‹çš„ model æ–¹æ³•ï¼Œå¯¹è¾“å…¥çš„å›¾åƒæˆ–è§†é¢‘è¿›è¡ŒæŽ¨ç†ï¼Œå¹¶å¾—åˆ°ç›®æ ‡æ£€æµ‹ç»“æžœã€‚
                self.pred = non_max_suppression(self.pre, self.conf_thres, self.iou_thres, None, False, max_det=10)
                if self.pred == None:
                    t = time.time() - t
                    return
                for det in self.pred[0]:
                    count += 1
                    if count > 1:
                        for [a, b] in C:
                            q = abs(int(det[0]) - a)
                            w = abs(int(det[1]) - b)
                            if q <= 5 and w <= 5:
                                ab = False
                                break
                            ab = True
                    else:
                        ab = True
                    if ab:
                        xyxy = (det[0], det[1], det[2], det[3])
                        cls = det[5]
                        conf = det[4]
                        ty = self.classes[int(cls)] + str(count) if int(det[5]) in lase_type else self.classes[int(cls)]
                        self.retu[ty] = list(int(x) for x in xyxy)
                        label = f'{self.classes[int(cls)]} {conf:.2f}'
                        cv2.rectangle(self.frame, (int(xyxy[0]), int(xyxy[1])), (int(xyxy[2]), int(xyxy[3])), (0, 255, 0),
                                      2)
                        cv2.putText(self.frame, label, (int(xyxy[0]), int(xyxy[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,
                                    (0, 255, 0), 2)
                        lase_type.append(int(det[5]))
                    C.append([int(det[0]), int(det[1])])
                print(self.retu)
                t = time.time() - t

    def date_intaract(self):
        self.shared_dict = self.retu
        self.shared_frame = self.frame

if __name__=='__main__':

    app = QApplication(sys.argv)
    ex = CameraUI()
    sys.exit(app.exec_())

