# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license




import argparse
import os
import platform
import sys
from pathlib import Path

import torch
from ultralytics.yolo.utils.ops import scale_coords

FILE = Path(__file__).resolve()#è·å–å½“å‰ç›®å½•(detect.py)çš„(ä½¿ç”¨relsove)ç»å¯¹è·¯å¾„,å¹¶å°†å…¶èµ‹å€¼ç»™å˜é‡FILE F:\yolov5-7.0\mydetect.py
ROOT = FILE.parents[0]  # YOLOv5 root directory è·å–ä¸Šä¸€çº§ç›®å½• F:\yolov5-7.0
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))  # add ROOT to PATH
ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relativeï¼Œç»å¯¹è·¯å¾„è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„ F:\yolov5-7.0\mydetect.py
from models.common import DetectMultiBackend
from utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadScreenshots, LoadStreams
from utils.general import (LOGGER, Profile, check_file, check_img_size, check_imshow, check_requirements, colorstr, cv2,
                           increment_path, non_max_suppression, print_args, scale_boxes, strip_optimizer, xyxy2xywh)
from utils.plots import Annotator, colors, save_one_box
from utils.torch_utils import select_device, smart_inference_mode


source='1'
weights='yolov5s.pt'
device='cpu'
device = select_device(device=device)#GPU

model = DetectMultiBackend(weights, device=device, dnn=False, data='data/coco128.yaml', fp16=False)
stride, names, pt = model.stride, model.names, model.pt# è·å–æ¨¡å‹çš„æ­¥å¹…ã€ç±»åˆ«åç§°å’Œæƒé‡æ–‡ä»¶è·¯å¾„

#è®¾ç½®é˜ˆå€¼å’ŒIOUé˜ˆå€¼
conf_thres = 0.8
iou_thres = 1.0

classes = ['person', 'car', 'truck', 'bus']

# æ‰“å¼€æ‘„åƒå¤´
cap = cv2.VideoCapture(0)
model.warmup(imgsz=(1 , 3, 640 ,480))
while True:
    # è¯»å–å¸§
    ret, frame = cap.read()
    frame = cv2.resize(frame,(640,480))
    cv2.imshow('frame', frame)
    # å°†å¸§è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼
    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    img = torch.from_numpy(img).to(device).float() / 255.0
    img = img.permute(2, 0, 1).unsqueeze(0)
    if len(img.shape) == 3:
        img = img[None]  # expand for batch dimå¦‚æœå¼ é‡çš„ç»´åº¦ä¸º 3ï¼Œåˆ™åœ¨ç¬¬ 0 ç»´ä¸Šæ·»åŠ ä¸€ä¸ªç»´åº¦ï¼Œä»¥ä¾¿å°†å…¶æ‰©å±•ä¸ºæ‰¹æ¬¡å¤§å°ä¸º 1 çš„å¼ é‡ã€‚
    print(img.shape)
    pre  = model.model(img, augment=False)  # è°ƒç”¨ YOLOv5 æ¨¡å‹çš„ model æ–¹æ³•ï¼Œå¯¹è¾“å…¥çš„å›¾åƒæˆ–è§†é¢‘è¿›è¡Œæ¨ç†ï¼Œå¹¶å¾—åˆ°ç›®æ ‡æ£€æµ‹ç»“æœã€‚
    pred = non_max_suppression(pre, conf_thres, iou_thres, None, False , max_det=10)

    for det in pred[0]:
        xyxy=(det[0],det[1],det[2],det[3])
        cls=det[5]
        conf=det[4]
        label = f'{classes[int(cls)]} {conf:.2f}'
        cv2.rectangle(frame, (int(xyxy[0]), int(xyxy[1])), (int(xyxy[2]), int(xyxy[3])), (0, 255, 0), 2)
        cv2.putText(frame, label, (int(xyxy[0]), int(xyxy[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    # æ˜¾ç¤ºç»“æœ

    cv2.imshow('frame2', frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
# é‡Šæ”¾èµ„æº
cap.release()
cv2.destroyAllWindows()




